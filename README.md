Benchmarking Join Suggestions
===

This repository contains the code used to run a benchmark on join suggestion algorithms.

Datasets are sourced from d3m and augmentation candidates are obtained using Auctus. 
The downstream performance is tested using the ML tasks reported in the metadata provided
by d3m. 

Given the augmentation candidates, additional candidates are generated by creating
new, redudant versions of the already known datasets. This is done to reflect 
real-life data analysis operations and table augmentations. 

# Scripts
`main_dataprep.py` is used to prepare the candidate set given a list of datasets. 


## Logging
- [mlflow](https://mlflow.org)
