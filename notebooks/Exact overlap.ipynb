{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this notebook we try to evaluate the exact overlap between a base table and\n",
    "the candidate tables. This is to observe whether MinHash is a good proxy of this \n",
    "metric over \"small\" data lakes. \n",
    "\n",
    "Note that this approach does not scale (that's what MinHash and Lazo are for, \n",
    "after all!). \n",
    "\n",
    "However, our use case should be small enough for this to not be a problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/soda/rcappuzz/work/benchmark-join-suggestions\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import src.methods.profiling as jp\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdata_root_dir = Path(\"data/metadata/\")\n",
    "yadl_case = \"binary\"\n",
    "mdata_path = Path(mdata_root_dir, yadl_case)\n",
    "\n",
    "base_table_path = \"data/source_tables/movies-yadl-ax.parquet\"\n",
    "df_base = pl.read_parquet(base_table_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_structures.indices import MinHashIndex\n",
    "import pickle\n",
    "index = MinHashIndex()\n",
    "with open(\"data/metadata/_indices/binary/minhash_index.pickle\", \"rb\") as fp:\n",
    "    input_dict = pickle.load(fp)\n",
    "    index.load_index(index_dict=input_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring the exact overlap between the query column and every other column in the data lake\n",
    "# Overlap is saved in `overlap_dict`\n",
    "overlap_dict = {}\n",
    "for f in mdata_path.glob(\"*.json\"):\n",
    "    with open(f) as fp:\n",
    "        mdata = json.load(fp)\n",
    "        cnd_path = mdata[\"full_path\"]\n",
    "        cnd_hash = mdata[\"hash\"]\n",
    "        df_cnd = pl.read_parquet(cnd_path)\n",
    "        for col in df_cnd.columns:\n",
    "            pair = (cnd_hash, col)\n",
    "            cont = jp.measure_containment(df_base, df_cnd, left_on=[\"col_to_embed\"], right_on=[col])\n",
    "            overlap_dict[pair] = cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to hold the dictionaries.\n",
    "df_overlap = pl.from_dict({\"key\": list(overlap_dict.keys()), \"overlap\": list(overlap_dict.values())})\n",
    "df_overlap = df_overlap.with_columns(\n",
    "    pl.col(\"key\").list.to_struct().struct.rename_fields([\"hash\", \"col\"])).unnest(\"key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column that marks as \"true\" all columns with overlap higher than `threshold`\n",
    "threshold = 0.1\n",
    "df_true = df_overlap.with_columns(\n",
    "    pl.when(\n",
    "        pl.col(\"overlap\") >= threshold,\n",
    "    ).then(\n",
    "        1\n",
    "    ).otherwise(\n",
    "        0\n",
    "    ).alias(\"mask_true\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# overlap_list = []\n",
    "# for f in mdata_path.glob(\"*.json\"):\n",
    "#     with open(f) as fp:\n",
    "#         mdata = json.load(fp)\n",
    "#         cnd_path = mdata[\"full_path\"]\n",
    "#         cnd_hash = mdata[\"hash\"]\n",
    "#         df_cnd = pl.read_parquet(cnd_path)\n",
    "#         for col in df_cnd.columns:\n",
    "#             pair = (cnd_hash, col)\n",
    "#             cont = jp.measure_containment_join(df_base, df_cnd, left_on=[\"col_to_embed\"], right_on=[col])\n",
    "#             overlap_list.append((pair, cont))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying index for any candidates\n",
    "query_result = index.query_index(df_base[\"col_to_embed\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the same dataframe as before for prediction\n",
    "ll = [[row[i] for row in query_result] for i in range(3)]\n",
    "df_pred = pl.from_dict(dict(zip([\"hash\", \"col\", \"score\"], ll)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two tables to measure recall \n",
    "combined = df_true.join(\n",
    "    df_pred, \n",
    "    on=[\"hash\", \"col\"],\n",
    "    how=\"left\"\n",
    ").with_columns(\n",
    "    pl.when(\n",
    "        pl.col(\"score\").is_not_null(),\n",
    "    ).then(\n",
    "        1\n",
    "    ).otherwise(\n",
    "        0\n",
    "    ).alias(\"mask_pred\")\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the F1 Score\n",
    "In this scenario:\n",
    "- `TP`: Matches with `overlap` >= `threshold` found by Minhash\n",
    "- `FP`: Matches with `overlap` < `threshold`, yet marked as matches by Minhash\n",
    "- `FN`: Matches with `overlap` >= `threshold` missed by Minhash\n",
    "- `TN`: Matches with `overlap` < `threshold` not returned by Minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measuring F1 score\n",
    "c_df = combined.select(\n",
    "    pl.col(\"mask_true\"),\n",
    "    pl.col(\"mask_pred\")\n",
    ").to_pandas()\n",
    "metrics.f1_score(c_df[\"mask_true\"], c_df[\"mask_pred\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_table(fpath, df_base):\n",
    "    overlap_dict = {}\n",
    "    with open(fpath) as fp:\n",
    "        mdata = json.load(fp)\n",
    "        cnd_path = mdata[\"full_path\"]\n",
    "        cnd_hash = mdata[\"hash\"]\n",
    "        df_cnd = pl.read_parquet(cnd_path)\n",
    "        for col in df_cnd.columns:\n",
    "            pair = (cnd_hash, col)\n",
    "            cont = jp.measure_containment(df_base, df_cnd, left_on=[\"col_to_embed\"], right_on=[col])\n",
    "            overlap_dict[pair] = cont\n",
    "    return overlap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2256/4080 [00:21<00:23, 77.46it/s] /home/soda/rcappuzz/mambaforge/envs/bench/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "                                                    \r"
     ]
    }
   ],
   "source": [
    "yadl_case = \"wordnet\"\n",
    "mdata_path = Path(mdata_root_dir, yadl_case)\n",
    "\n",
    "# Building the pairwise distance with joblib\n",
    "r = Parallel(n_jobs=8, verbose=0)(\n",
    "    delayed(evaluate_one_table)(\n",
    "        fpath, df_base\n",
    "    )\n",
    "    for idx, fpath in tqdm(\n",
    "        enumerate(mdata_path.glob(\"*.json\")),\n",
    "        position=0,\n",
    "        leave=False,\n",
    "        total=sum([1 for _ in mdata_path.glob(\"*.json\")]),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_dict = {key: val for result in r for key, val in result.items()}\n",
    "df_overlap = pl.from_dict({\"key\": list(overlap_dict.keys()), \"overlap\": list(overlap_dict.values())})\n",
    "df_overlap = df_overlap.with_columns(\n",
    "    pl.col(\"key\").list.to_struct().struct.rename_fields([\"hash\", \"col\"])).unnest(\"key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column that marks as \"true\" all columns with overlap higher than `threshold`\n",
    "threshold = 0.1\n",
    "df_true = df_overlap.with_columns(\n",
    "    pl.when(\n",
    "        pl.col(\"overlap\") >= threshold,\n",
    "    ).then(\n",
    "        1\n",
    "    ).otherwise(\n",
    "        0\n",
    "    ).alias(\"mask_true\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying index for any candidates\n",
    "index = MinHashIndex()\n",
    "with open(\"data/metadata/_indices/wordnet_big/minhash_index.pickle\", \"rb\") as fp:\n",
    "    input_dict = pickle.load(fp)\n",
    "    index.load_index(index_dict=input_dict)\n",
    "query_result = index.query_index(df_base[\"col_to_embed\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the same dataframe as before for prediction\n",
    "ll = [[row[i] for row in query_result] for i in range(3)]\n",
    "df_pred = pl.from_dict(dict(zip([\"hash\", \"col\", \"score\"], ll)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two tables to measure recall \n",
    "combined = df_true.join(\n",
    "    df_pred, \n",
    "    on=[\"hash\", \"col\"],\n",
    "    how=\"left\"\n",
    ").with_columns(\n",
    "    pl.when(\n",
    "        pl.col(\"score\").is_not_null(),\n",
    "    ).then(\n",
    "        1\n",
    "    ).otherwise(\n",
    "        0\n",
    "    ).alias(\"mask_pred\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.588\n"
     ]
    }
   ],
   "source": [
    "# Prepare a simplified df\n",
    "c_df = combined.select(\n",
    "    pl.col(\"mask_true\"),\n",
    "    pl.col(\"mask_pred\")\n",
    ").to_pandas()\n",
    "\n",
    "# Measure the F1 score\n",
    "f1 = metrics.f1_score(c_df[\"mask_true\"], c_df[\"mask_pred\"])\n",
    "print(f\"F1 score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (24, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>hash</th><th>col</th><th>overlap</th><th>mask_true</th><th>score</th><th>mask_pred</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>i32</td><td>i64</td><td>i32</td></tr></thead><tbody><tr><td>&quot;4ac9c8c52c4e62…</td><td>&quot;wroteMusicFor&quot;</td><td>0.63126</td><td>1</td><td>20</td><td>1</td></tr><tr><td>&quot;31dd169ccb1ae2…</td><td>&quot;created&quot;</td><td>0.011597</td><td>0</td><td>20</td><td>1</td></tr><tr><td>&quot;31dd169ccb1ae2…</td><td>&quot;wroteMusicFor&quot;</td><td>0.062994</td><td>0</td><td>10</td><td>1</td></tr><tr><td>&quot;435dd1be6f5a53…</td><td>&quot;wroteMusicFor&quot;</td><td>0.527412</td><td>1</td><td>20</td><td>1</td></tr><tr><td>&quot;9acceb4c65180a…</td><td>&quot;created&quot;</td><td>0.089879</td><td>0</td><td>20</td><td>1</td></tr><tr><td>&quot;5ba095067e3b32…</td><td>&quot;subject&quot;</td><td>0.742488</td><td>1</td><td>20</td><td>1</td></tr><tr><td>&quot;3575088b33b2f1…</td><td>&quot;created&quot;</td><td>0.030047</td><td>0</td><td>10</td><td>1</td></tr><tr><td>&quot;9d60169c13316d…</td><td>&quot;created&quot;</td><td>0.089352</td><td>0</td><td>20</td><td>1</td></tr><tr><td>&quot;63f0aeab836798…</td><td>&quot;subject&quot;</td><td>0.964681</td><td>1</td><td>20</td><td>1</td></tr><tr><td>&quot;c65197005e108f…</td><td>&quot;created&quot;</td><td>0.020559</td><td>0</td><td>20</td><td>1</td></tr><tr><td>&quot;58d1bf956ebed8…</td><td>&quot;created&quot;</td><td>0.062731</td><td>0</td><td>20</td><td>1</td></tr><tr><td>&quot;58d1bf956ebed8…</td><td>&quot;wroteMusicFor&quot;</td><td>0.510807</td><td>1</td><td>20</td><td>1</td></tr><tr><td>&quot;b606498cb9dc3f…</td><td>&quot;wroteMusicFor&quot;</td><td>0.205851</td><td>1</td><td>20</td><td>1</td></tr><tr><td>&quot;042c9ecc1f55c8…</td><td>&quot;wroteMusicFor&quot;</td><td>0.060886</td><td>0</td><td>10</td><td>1</td></tr><tr><td>&quot;5830c3720606b9…</td><td>&quot;subject&quot;</td><td>0.163943</td><td>1</td><td>20</td><td>1</td></tr><tr><td>&quot;d08c65651de561…</td><td>&quot;created&quot;</td><td>0.023985</td><td>0</td><td>20</td><td>1</td></tr><tr><td>&quot;d08c65651de561…</td><td>&quot;wroteMusicFor&quot;</td><td>0.236953</td><td>1</td><td>20</td><td>1</td></tr><tr><td>&quot;02e011af482000…</td><td>&quot;subject&quot;</td><td>0.220348</td><td>1</td><td>null</td><td>0</td></tr><tr><td>&quot;061fa2f5eaae62…</td><td>&quot;created&quot;</td><td>0.02952</td><td>0</td><td>10</td><td>1</td></tr><tr><td>&quot;4cc68caf748967…</td><td>&quot;subject&quot;</td><td>0.008962</td><td>0</td><td>10</td><td>1</td></tr><tr><td>&quot;b76b08208a7639…</td><td>&quot;created&quot;</td><td>0.074064</td><td>0</td><td>20</td><td>1</td></tr><tr><td>&quot;b76b08208a7639…</td><td>&quot;wroteMusicFor&quot;</td><td>0.60543</td><td>1</td><td>20</td><td>1</td></tr><tr><td>&quot;81ee88e56cd4d0…</td><td>&quot;wroteMusicFor&quot;</td><td>0.24855</td><td>1</td><td>20</td><td>1</td></tr><tr><td>&quot;b817608d805548…</td><td>&quot;wroteMusicFor&quot;</td><td>0.064312</td><td>0</td><td>10</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (24, 6)\n",
       "┌──────────────────────────────────┬───────────────┬──────────┬───────────┬───────┬───────────┐\n",
       "│ hash                             ┆ col           ┆ overlap  ┆ mask_true ┆ score ┆ mask_pred │\n",
       "│ ---                              ┆ ---           ┆ ---      ┆ ---       ┆ ---   ┆ ---       │\n",
       "│ str                              ┆ str           ┆ f64      ┆ i32       ┆ i64   ┆ i32       │\n",
       "╞══════════════════════════════════╪═══════════════╪══════════╪═══════════╪═══════╪═══════════╡\n",
       "│ 4ac9c8c52c4e62e70570d5a24e4b7d26 ┆ wroteMusicFor ┆ 0.63126  ┆ 1         ┆ 20    ┆ 1         │\n",
       "│ 31dd169ccb1ae2dd83dc4a19cabc8d0c ┆ created       ┆ 0.011597 ┆ 0         ┆ 20    ┆ 1         │\n",
       "│ 31dd169ccb1ae2dd83dc4a19cabc8d0c ┆ wroteMusicFor ┆ 0.062994 ┆ 0         ┆ 10    ┆ 1         │\n",
       "│ 435dd1be6f5a53f04e91186ec10b3f1c ┆ wroteMusicFor ┆ 0.527412 ┆ 1         ┆ 20    ┆ 1         │\n",
       "│ …                                ┆ …             ┆ …        ┆ …         ┆ …     ┆ …         │\n",
       "│ b76b08208a763910cb7f8747c3f6b05b ┆ created       ┆ 0.074064 ┆ 0         ┆ 20    ┆ 1         │\n",
       "│ b76b08208a763910cb7f8747c3f6b05b ┆ wroteMusicFor ┆ 0.60543  ┆ 1         ┆ 20    ┆ 1         │\n",
       "│ 81ee88e56cd4d0b9b8ff30e8a1eb05ec ┆ wroteMusicFor ┆ 0.24855  ┆ 1         ┆ 20    ┆ 1         │\n",
       "│ b817608d805548f3fe2a200c75d249d5 ┆ wroteMusicFor ┆ 0.064312 ┆ 0         ┆ 10    ┆ 1         │\n",
       "└──────────────────────────────────┴───────────────┴──────────┴───────────┴───────┴───────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at the positive matches\n",
    "combined.filter(\n",
    "    (pl.col(\"mask_true\") == 1) | (pl.col(\"mask_pred\") == 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative:       19352\n",
      "False Positive:         13\n",
      "False Negative:          1\n",
      "True Positive:          10\n",
      "Recall:             0.909\n",
      "Precision:          0.435\n"
     ]
    }
   ],
   "source": [
    "# Preparing confusion matrix\n",
    "conf_m = metrics.confusion_matrix(c_df[\"mask_true\"], c_df[\"mask_pred\"])\n",
    "tn, fp, fn, tp = conf_m.ravel()\n",
    "print(f\"{'True Negative:':<20}{tn:>6}\")\n",
    "print(f\"{'False Positive:':<20}{fp:>6}\")\n",
    "print(f\"{'False Negative:':<20}{fn:>6}\")\n",
    "print(f\"{'True Positive:':<20}{tp:>6}\")\n",
    "recall = metrics.recall_score(c_df[\"mask_true\"], c_df[\"mask_pred\"])\n",
    "print(f\"{'Recall:':<20}{recall:.3f}\")\n",
    "precision = metrics.precision_score(c_df[\"mask_true\"], c_df[\"mask_pred\"])\n",
    "print(f\"{'Precision:':<20}{precision:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = combined.select(\n",
    "    pl.col(\"overlap\").fill_null(0).alias(\"y_true\"),\n",
    "    pl.col(\"score\").fill_null(0).alias(\"y_pred\")/100,\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45212755190656906"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(cc[\"y_true\"], cc[\"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
