{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/soda/rcappuzz/work/benchmark-join-suggestions\n"
     ]
    }
   ],
   "source": [
    "cd ~/bench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was used to prepare the experimental results that were in the original VLDB 2024 submission (before any \n",
    "updates made during the revision period).\n",
    "\n",
    "It was left in for reference, but the results and files may have been moved/removed over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from src.utils.logging import read_and_process, read_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = pl.Config()\n",
    "cfg.set_fmt_str_lengths(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_path = Path(\"results/overall\")\n",
    "overall_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full run depleted Wordnet aggregation first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results/logs/0363-mp1a3by4`\n",
    "- Full run\n",
    "- All tables\n",
    "- Wordnet full\n",
    "- Aggregation first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_path = \"results/logs/0363-mp1a3by4\"\n",
    "df_raw = read_logs(exp_name=None, exp_path=r_path)\n",
    "df_raw = df_raw.fill_null(0).with_columns(pl.lit(0.0).alias(\"auc\"), pl.lit(0.0).alias(\"f1score\"))\n",
    "overall_list.append(df_raw)\n",
    "df_raw.write_parquet(Path(dest_path, \"wordnet_general_first.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full run depleted Wordnet aggregation mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results/logs/0383-ptn1bncl`\n",
    "- Full run\n",
    "- All tables\n",
    "- Wordnet full\n",
    "- Aggregation mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_path = \"results/logs/0383-ptn1bncl\"\n",
    "df_raw = read_logs(exp_name=None, exp_path=r_path)\n",
    "df_raw = df_raw.fill_null(0).with_columns(pl.lit(0.0).alias(\"auc\"), pl.lit(0.0).alias(\"f1score\"))\n",
    "df_raw.write_parquet(Path(dest_path, \"wordnet_general_mean.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full run full tables Wordnet aggregation first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results/logs/0389-4jmvw4qc`\n",
    "- Full run\n",
    "- Full tables\n",
    "- All tables\n",
    "- Wordnet full\n",
    "- Aggregation first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_path = \"results/logs/0389-4jmvw4qc\"\n",
    "df_raw = read_logs(exp_name=None, exp_path=r_path)\n",
    "df_raw = df_raw.fill_null(0).with_columns(pl.lit(0.0).alias(\"auc\"), pl.lit(0.0).alias(\"f1score\"))\n",
    "df_raw.write_parquet(Path(dest_path, \"wordnet_general_first_full-tables.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full run Binary aggregation first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results/logs/0387-df7e67z4`\n",
    "- Full run\n",
    "- Full tables\n",
    "- All tables\n",
    "- Binary\n",
    "- Aggregation first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_path = \"results/logs/0387-df7e67z4\"\n",
    "df_raw = read_logs(exp_name=None, exp_path=r_path)\n",
    "df_raw = df_raw.fill_null(0).with_columns(pl.lit(0.0).alias(\"auc\"), pl.lit(0.0).alias(\"f1score\"))\n",
    "overall_list.append(df_raw)\n",
    "df_raw.write_parquet(Path(dest_path, \"binary_general_first.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Data full run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "paths = [\n",
    "    \"results/logs/0372-35kmeaz3\",\n",
    "    \"results/logs/0373-csmtrlcd\",\n",
    "    \"results/logs/0374-7226gvfk\",\n",
    "    \"results/logs/0376-c8xw7pry\",\n",
    "    \"results/logs/0377-q83k1stf\",\n",
    "    \"results/logs/0381-roaef1ce\",\n",
    "]\n",
    "```\n",
    "`results/logs/0375-mjbya9c5` is a duplicate of 0374 (the configuration is the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"results/logs/0372-35kmeaz3\",\n",
    "    \"results/logs/0373-csmtrlcd\",\n",
    "    \"results/logs/0374-7226gvfk\",\n",
    "    \"results/logs/0376-c8xw7pry\",\n",
    "    \"results/logs/0377-q83k1stf\",\n",
    "    \"results/logs/0381-roaef1ce\",\n",
    "]\n",
    "\n",
    "open_data_list = []\n",
    "\n",
    "for path in paths:\n",
    "    df_raw = read_logs(exp_name=None, exp_path=path)\n",
    "    df_raw = df_raw.fill_null(0).with_columns(pl.lit(0.0).alias(\"auc\"), pl.lit(0.0).alias(\"f1score\"))\n",
    "    open_data_list.append(df_raw)\n",
    "\n",
    "df_concat = pl.concat(open_data_list)\n",
    "df_concat.write_parquet(Path(dest_path, \"open_data_general_first.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    # schools-depleted\n",
    "    \"results/logs/0407-4jg7s2om\",\n",
    "    \"results/logs/0408-ydr7giul\",\n",
    "    \"results/logs/0409-nah78lu9\",\n",
    "]\n",
    "\n",
    "open_data_list = []\n",
    "\n",
    "for path in paths:\n",
    "    df_raw = read_logs(exp_name=None, exp_path=path)\n",
    "    df_raw = df_raw.fill_null(0)\n",
    "    df_raw = df_raw.with_columns(pl.col(\"auc\").alias(\"r2score\"), pl.lit(0).alias(\"rmse\"))\n",
    "    open_data_list.append(df_raw)\n",
    "\n",
    "df_concat = pl.concat(open_data_list)\n",
    "df_concat.write_parquet(Path(dest_path, \"open_data_schools_first.parquet\"))\n",
    "# overall_list.append(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('scenario_id', Int64), ('status', String), ('target_dl', String), ('jd_method', String), ('base_table', String), ('query_column', String), ('estimator', String), ('aggregation', String), ('chosen_model', String), ('fold_id', Int64), ('time_fit', Float64), ('time_predict', Float64), ('time_run', Float64), ('time_prepare', Float64), ('time_model_train', Float64), ('time_join_train', Float64), ('time_model_predict', Float64), ('time_join_predict', Float64), ('peak_fit', Float64), ('peak_predict', Float64), ('peak_test', Float64), ('r2score', Float64), ('rmse', Float64), ('f1score', Float64), ('auc', Float64), ('n_cols', String), ('budget_type', String), ('budget_amount', Int64), ('epsilon', Float64)])\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    \"results/logs/0372-35kmeaz3\",\n",
    "    \"results/logs/0373-csmtrlcd\",\n",
    "    \"results/logs/0374-7226gvfk\",\n",
    "    \"results/logs/0376-c8xw7pry\",\n",
    "    \"results/logs/0377-q83k1stf\",\n",
    "    \"results/logs/0381-roaef1ce\",\n",
    "]\n",
    "paths_schools = [\n",
    "    \"results/logs/0407-4jg7s2om\",\n",
    "    \"results/logs/0408-ydr7giul\",\n",
    "    \"results/logs/0409-nah78lu9\",\n",
    "]\n",
    "\n",
    "open_data_list = []\n",
    "\n",
    "for path in paths:\n",
    "    df_raw = read_logs(exp_name=None, exp_path=path)\n",
    "    df_raw = df_raw.fill_null(0).with_columns(pl.lit(0.0).alias(\"auc\"), pl.lit(0.0).alias(\"f1score\"))\n",
    "    open_data_list.append(df_raw)\n",
    "for path in paths_schools:\n",
    "    df_raw = read_logs(exp_name=None, exp_path=path)\n",
    "    df_raw = df_raw.fill_null(0)\n",
    "    df_raw = df_raw.with_columns(pl.col(\"auc\").alias(\"r2score\"), pl.lit(0.0).alias(\"rmse\"))\n",
    "    open_data_list.append(df_raw)\n",
    "df_concat = pl.concat(open_data_list)\n",
    "print(df_concat.schema)\n",
    "\n",
    "df_concat.write_parquet(Path(dest_path, \"open_data_all_first.parquet\"))\n",
    "overall_list.append(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('scenario_id', Int64),\n",
       "             ('status', String),\n",
       "             ('target_dl', String),\n",
       "             ('jd_method', String),\n",
       "             ('base_table', String),\n",
       "             ('query_column', String),\n",
       "             ('estimator', String),\n",
       "             ('aggregation', String),\n",
       "             ('chosen_model', String),\n",
       "             ('fold_id', Int64),\n",
       "             ('time_fit', Float64),\n",
       "             ('time_predict', Float64),\n",
       "             ('time_run', Float64),\n",
       "             ('time_prepare', Float64),\n",
       "             ('time_model_train', Float64),\n",
       "             ('time_join_train', Float64),\n",
       "             ('time_model_predict', Float64),\n",
       "             ('time_join_predict', Float64),\n",
       "             ('peak_fit', Float64),\n",
       "             ('peak_predict', Float64),\n",
       "             ('peak_test', Float64),\n",
       "             ('r2score', Float64),\n",
       "             ('rmse', Float64),\n",
       "             ('f1score', Float64),\n",
       "             ('auc', Float64),\n",
       "             ('n_cols', String),\n",
       "             ('budget_type', String),\n",
       "             ('budget_amount', Int64),\n",
       "             ('epsilon', Float64)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('scenario_id', Int64), ('status', String), ('target_dl', String), ('jd_method', String), ('base_table', String), ('query_column', String), ('estimator', String), ('aggregation', String), ('chosen_model', String), ('fold_id', Int64), ('time_fit', Float64), ('time_predict', Float64), ('time_run', Float64), ('time_prepare', Float64), ('time_model_train', Float64), ('time_join_train', Float64), ('time_model_predict', Float64), ('time_join_predict', Float64), ('peak_fit', Float64), ('peak_predict', Float64), ('peak_test', Float64), ('r2score', Float64), ('rmse', Float64), ('f1score', Float64), ('auc', Float64), ('n_cols', String), ('budget_type', String), ('budget_amount', Int64), ('epsilon', Float64)])\n",
      "OrderedDict([('scenario_id', Int64), ('status', String), ('target_dl', String), ('jd_method', String), ('base_table', String), ('query_column', String), ('estimator', String), ('aggregation', String), ('chosen_model', String), ('fold_id', Int64), ('time_fit', Float64), ('time_predict', Float64), ('time_run', Float64), ('time_prepare', Float64), ('time_model_train', Float64), ('time_join_train', Float64), ('time_model_predict', Float64), ('time_join_predict', Float64), ('peak_fit', Float64), ('peak_predict', Float64), ('peak_test', Float64), ('r2score', Float64), ('rmse', Float64), ('f1score', Float64), ('auc', Float64), ('n_cols', String), ('budget_type', String), ('budget_amount', Int64), ('epsilon', Float64)])\n",
      "OrderedDict([('scenario_id', Int64), ('status', String), ('target_dl', String), ('jd_method', String), ('base_table', String), ('query_column', String), ('estimator', String), ('aggregation', String), ('chosen_model', String), ('fold_id', Int64), ('time_fit', Float64), ('time_predict', Float64), ('time_run', Float64), ('time_prepare', Float64), ('time_model_train', Float64), ('time_join_train', Float64), ('time_model_predict', Float64), ('time_join_predict', Float64), ('peak_fit', Float64), ('peak_predict', Float64), ('peak_test', Float64), ('r2score', Float64), ('rmse', Float64), ('f1score', Float64), ('auc', Float64), ('n_cols', String), ('budget_type', String), ('budget_amount', Int64), ('epsilon', Float64)])\n"
     ]
    }
   ],
   "source": [
    "for df in overall_list:\n",
    "    print(df.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall = pl.concat(overall_list)\n",
    "df_overall.write_parquet(Path(dest_path, \"overall_first.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation WORDNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results/logs/0382-bfft0brr`\n",
    "- Only best single join and highest containment\n",
    "- All tables\n",
    "- Wordnet full\n",
    "- DFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_path = \"results/logs/0382-bfft0brr\"\n",
    "df_raw = read_logs(exp_name=None, exp_path=r_path)\n",
    "# overall_list.append(df_raw)\n",
    "df_raw.write_parquet(Path(dest_path, \"wordnet_dfs.parquet\"))\n",
    "drop = [\n",
    "    \"status\",\n",
    "    \"rmse\",\n",
    "    \"f1score\",\n",
    "    \"auc\",\n",
    "    \"n_cols\",\n",
    "    \"budget_type\",\n",
    "    \"budget_amount\",\n",
    "    \"epsilon\",\n",
    "]\n",
    "df_first = pl.read_parquet(Path(dest_path, \"wordnet_general_first.parquet\"))\n",
    "df_mean = pl.read_parquet(Path(dest_path, \"wordnet_general_mean.parquet\"))\n",
    "df_c = pl.concat([df_first.drop(drop), df_mean.drop(drop), df_raw.drop(drop)])\n",
    "f = {\"jd_method\": \"exact_matching\"}\n",
    "df_aggr = df_c.filter(**f).filter(\n",
    "    pl.col(\"estimator\").is_in([\"highest_containment\", \"best_single_join\"])\n",
    ")\n",
    "df_aggr = df_aggr.filter(\n",
    "    pl.col(\"base_table\").is_in(\n",
    "        df_aggr.filter(pl.col(\"aggregation\") == \"dfs\").select(pl.col(\"base_table\"))\n",
    "    )\n",
    ")\n",
    "df_aggr.write_parquet(Path(dest_path, \"wordnet_aggr.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>base_table</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;company_employees-yadl-depleted&quot;</td></tr><tr><td>&quot;us_county_population-yadl-depleted&quot;</td></tr><tr><td>&quot;us_accidents-yadl-depleted&quot;</td></tr><tr><td>&quot;movies_vote-yadl-depleted&quot;</td></tr><tr><td>&quot;us_elections-yadl-depleted&quot;</td></tr><tr><td>&quot;movies-yadl-depleted&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 1)\n",
       "┌────────────────────────────────────┐\n",
       "│ base_table                         │\n",
       "│ ---                                │\n",
       "│ str                                │\n",
       "╞════════════════════════════════════╡\n",
       "│ company_employees-yadl-depleted    │\n",
       "│ us_county_population-yadl-depleted │\n",
       "│ us_accidents-yadl-depleted         │\n",
       "│ movies_vote-yadl-depleted          │\n",
       "│ us_elections-yadl-depleted         │\n",
       "│ movies-yadl-depleted               │\n",
       "└────────────────────────────────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aggr.select(pl.col(\"base_table\").unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation BINARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results/logs/0386-sh4fb419`\n",
    "- Only best single join and highest containment\n",
    "- All tables\n",
    "- Binary\n",
    "- DFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_path = \"results/logs/0386-sh4fb419\"\n",
    "df_raw = read_logs(exp_name=None, exp_path=r_path)\n",
    "# overall_list.append(df_raw)\n",
    "df_raw.write_parquet(Path(dest_path, \"binary_mean_dfs.parquet\"))\n",
    "df_base = pl.read_parquet(Path(dest_path, \"binary_general_first.parquet\"))\n",
    "drop = [\n",
    "    \"status\",\n",
    "    \"rmse\",\n",
    "    \"f1score\",\n",
    "    \"auc\",\n",
    "    \"n_cols\",\n",
    "    \"budget_type\",\n",
    "    \"budget_amount\",\n",
    "    \"epsilon\",\n",
    "]\n",
    "df_c = pl.concat([df_base.drop(drop), df_raw.drop(drop)])\n",
    "f = {\"jd_method\": \"exact_matching\"}\n",
    "df_aggr = df_c.filter(**f).filter(\n",
    "    pl.col(\"estimator\").is_in([\"highest_containment\", \"best_single_join\"])\n",
    ")\n",
    "df_aggr.write_parquet(Path(dest_path, \"binary_aggr.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Open Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results/logs/0412-0poz2985`\n",
    "- Only best single join and highest containment\n",
    "- All tables\n",
    "- Open Data\n",
    "- Mean DFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"results/logs/0412-0poz2985\",\n",
    "    \"results/logs/0413-f2lqxjym\",\n",
    "]\n",
    "\n",
    "open_data_list = []\n",
    "\n",
    "for path in paths:\n",
    "    df_raw = read_logs(exp_name=None, exp_path=path)\n",
    "    df_raw = df_raw.fill_null(0)\n",
    "    # df_raw = df_raw.with_columns(pl.col(\"auc\").alias(\"r2score\"), pl.lit(0).alias(\"rmse\"))\n",
    "    open_data_list.append(df_raw)\n",
    "df_aggr = pl.concat(open_data_list)\n",
    "df_aggr.write_parquet(Path(dest_path, \"open_data_us_mean_dfs.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('scenario_id', Int64), ('status', String), ('target_dl', String), ('jd_method', String), ('base_table', String), ('query_column', String), ('estimator', String), ('aggregation', String), ('chosen_model', String), ('fold_id', Int64), ('time_fit', Float64), ('time_predict', Float64), ('time_run', Float64), ('time_prepare', Float64), ('time_model_train', Float64), ('time_join_train', Float64), ('time_model_predict', Float64), ('time_join_predict', Float64), ('peak_fit', Float64), ('peak_predict', Float64), ('peak_test', Float64), ('r2score', Float64), ('rmse', Float64), ('f1score', Float64), ('auc', Float64), ('n_cols', String), ('budget_type', String), ('budget_amount', Int64), ('epsilon', Float64)])\n",
      "OrderedDict([('scenario_id', Int64), ('status', String), ('target_dl', String), ('jd_method', String), ('base_table', String), ('query_column', String), ('estimator', String), ('aggregation', String), ('chosen_model', String), ('fold_id', Int64), ('time_fit', Float64), ('time_predict', Float64), ('time_run', Float64), ('time_prepare', Float64), ('time_model_train', Float64), ('time_join_train', Float64), ('time_model_predict', Float64), ('time_join_predict', Float64), ('peak_fit', Float64), ('peak_predict', Float64), ('peak_test', Float64), ('r2score', Float64), ('rmse', Float64), ('f1score', String), ('auc', String), ('n_cols', String), ('budget_type', String), ('budget_amount', String), ('epsilon', String)])\n"
     ]
    }
   ],
   "source": [
    "print(df_base.schema)\n",
    "print(df_aggr.schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pl.read_parquet(Path(dest_path, \"open_data_general_first.parquet\"))\n",
    "drop = [\n",
    "    \"status\",\n",
    "    \"rmse\",\n",
    "    \"f1score\",\n",
    "    \"auc\",\n",
    "    \"n_cols\",\n",
    "    \"budget_type\",\n",
    "    \"budget_amount\",\n",
    "    \"epsilon\",\n",
    "]\n",
    "df_c = pl.concat([df_base.drop(drop), df_aggr.drop(drop)])\n",
    "f = {\"jd_method\": \"exact_matching\"}\n",
    "df_aggr = df_c.filter(**f).filter(\n",
    "    pl.col(\"estimator\").is_in([\"highest_containment\", \"best_single_join\"])\n",
    ")\n",
    "df_aggr.write_parquet(Path(dest_path, \"open_data_aggr.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wordnet = pl.read_parquet(Path(dest_path, \"wordnet_aggr.parquet\"))\n",
    "df_binary = pl.read_parquet(Path(dest_path, \"binary_aggr.parquet\"))\n",
    "df_open_data = pl.read_parquet(Path(dest_path, \"open_data_aggr.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggr_full  = pl.concat([df_wordnet, df_binary, df_open_data])\n",
    "df_aggr_full.write_parquet(Path(dest_path, \"overall_aggr.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
